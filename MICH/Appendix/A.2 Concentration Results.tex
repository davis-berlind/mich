\subsection{Concentration Results}
\label{app:concentration}

\subsubsection{Sums of sub-Gaussian and sub-Exponential Processes}

\begin{lemma}\label{lemma:sum-sub-gaussian}
If $\{X_i\}_{i=1}^n$ is a collection of random variables such that for each $i \in [n]$, $\E[X_i] = 0$ and $X_i \in \mathcal{SG}(\sigma_i)$ for some $\sigma_i > 0$, then letting $\boldsymbol{\sigma} = \{\sigma_i\}_{i=1}^n$, we have:
\begin{align*}
    \sum_{i=1}^n X_i \in 
    \begin{cases}
        \mathcal{SG}(\lVert \boldsymbol{\sigma}\rVert_2), &\text{if $\{X_i\}_{i=1}^n$ are mutually independent,} \\
        \mathcal{SG}(\lVert \boldsymbol{\sigma}\rVert_1), &\text{otherwise.}
    \end{cases}
\end{align*}
Similarly, if $X_i \in \mathcal{SE}(\nu_i, \alpha_i)$ for some $\sigma_i,\:\alpha_i > 0$, then letting $\boldsymbol{\nu} = \{\nu_i\}_{i=1}^n$ and $\boldsymbol{\alpha} = \{\alpha_i\}_{i=1}^n$ , we have:
\begin{align*}
    \sum_{i=1}^n X_i \in 
    \begin{cases}
        \mathcal{SE}(\lVert \boldsymbol{\nu}\rVert_2, \lVert \boldsymbol{\alpha}\rVert_\infty), &\text{if $\{X_i\}_{i=1}^n$ are mutually independent,} \\
        \mathcal{SE}(\lVert \boldsymbol{\nu}\rVert_1,  \lVert \boldsymbol{\alpha}\rVert_\infty), &\text{otherwise.}
    \end{cases}
\end{align*}
\end{lemma}

\begin{proof}
First suppose that $X_i \in \mathcal{SE}(\nu_i, \alpha_i)$ and that $\{X_i\}_{i=1}^n$ is a collection of independent random variables, then by independence:
\begin{align*}
    \E\left[\exp\left(\lambda \sum_{i=1}^n X_i\right)\right] &=  \prod_{i=1}^n \E\left[\exp\left(\lambda X_i\right)\right].
\end{align*}
Next, note that if $|\lambda| < \lVert \boldsymbol{\alpha}\rVert^{-1}_{\infty}$, then $|\lambda| < \alpha_i^{-1}$ for each $i \in [n]$ and thus:
\begin{align*}
    \E\left[\exp\left(\lambda X_i\right)\right] \leq \exp\left[\frac{\lambda^2\nu_{i}^2}{2}\right]
\end{align*}
which implies:
\begin{align*}
    \E\left[\exp\left(\lambda \sum_{i=1}^n X_i\right)\right] &\leq \exp\left[\frac{\lambda\sum_{i=1}^n\nu^2_i}{2}\right].
\end{align*}
So $\sum_{i=1}^n X_i \in \mathcal{SE}(\lVert \boldsymbol{\nu}\rVert_2, \lVert \boldsymbol{\alpha}\rVert_\infty)$. When $\{X_i\}_{i=1}^n$ are not independent, then for any $|\lambda| \leq \lVert \boldsymbol{\alpha}\rVert^{-1}_{\infty}$ and any collection of parameters $\{p_i\}_{i=1}^n$ such that $p_i > 0$ and $\sum_{i=1}^n p_i^{-1} = 1$, we have:
\begin{align*}
    \E\left[\exp\left(\lambda \sum_{i=1}^n X_i\right)\right] &= \E\left[ \prod_{i=1}^n \exp\left(\lambda X_i\right)\right] \\
    &\leq \prod_{i=1}^n \left(\E[\exp\left(p_i \lambda X_i\right)]\right)^{1/p_i} \tag{H\"older's inequality} \\
    &\leq \prod_{i=1}^n \left(\E\left[\exp\left(\frac{p^2_i\nu_i^2 \lambda^2}{2}\right)\right]\right)^{1/p_i} \tag{$X_i \in \mathcal{SE}(\nu_i,\alpha_i)$} \\
    &= \exp\left[\frac{\lambda^2\sum_{i=1}^n p_i \nu_i^2}{2}\right].
\end{align*}
Since our choice of $\{p_i\}_{i=1}^n$ was arbitrary so long as $p_i > 0$ and $\sum_{i=1}^n p_i^{-1} = 1$, we can set each $p_i = \frac{\lVert\boldsymbol{\nu}\rVert_1}{\nu_i},$ then we get:
\begin{align*}
    \E\left[\exp\left(\lambda \sum_{i=1}^n X_i\right)\right] &\leq \exp\left[\frac{\lambda \lVert \boldsymbol{\nu}\rVert^2_1}{2}\right]
\end{align*}
showing that $\sum_{i=1}^n X_i \in \mathcal{SE}(\lVert\boldsymbol{\nu}\rVert_1, \lVert \boldsymbol{\alpha}\rVert_\infty).$ The proof for the case where $X_i \in \mathcal{SG}(\sigma_i)$ follows an identical argument as above with $\sigma_i$ replacing $\nu_i$ and ignoring any constraints on $\lambda$. 

\end{proof}

\subsubsection{Sums of $\alpha$-Mixing Processes}

\begin{lemma}[\citealp{Padilla23} Lemma 3]\label{lemma:Padilla23}
Let $\nu > 0$ be given. Suppose that $\{X_t\}_{t=1}^\infty$ is a stationary $\alpha$-mixing time-series with mixing coefficients $\{\alpha_k\}_{k=0}^K$. Suppose that $\E[X_t] = 0$ and that there exist constants $\delta, \Delta, D_1, D_2 > 0$ such that:
\begin{align*}
    \sup_{t \geq 1}\; \E\left[\left|X_t\right|^{2+\delta+\Delta}\right] \leq D_1 
\end{align*}
and:
\begin{align*}
    \sum_{k=0}^\infty (k+1)^{\frac{\delta}{2}} \alpha_k^{\frac{\Delta}{2+\delta+\Delta}} \leq D_2.
\end{align*}
Then there exists some universal constant $C > 0$ such that for any $a \in (0,1)$:
\begin{align*}
    \Pr \left(\left|\sum_{t'=1}^t X_{t'}\right| \leq a^{-1}C\sqrt{t}\left[\log (\nu t) + 1\right], \;\sforall t\geq \nu^{-1}\right) 
    \geq 1 - a^2.
\end{align*}

\end{lemma}

\begin{lemma}\label{lemma:alpha-mix-sum}
Suppose that $\{X_t\}_{t\geq 1}$ is a stationary, $\alpha$-mixing processes with mixing coefficients and moments that satisfy the conditions of Lemma \ref{lemma:Padilla23}. Then for $T \geq 1$, $t_0 \in [T]$, and sequence $\{a_T\}_{T\geq 1}$ such that $a_T > 0$ and $\lim_{T\to\infty} a_T = \infty$, there exists a universal constant $C > 0$ such that:
\begin{align*}
    \Pr \left(\bigcup_{t=t_0 + 1}^{T}\left\{ \left|\sum_{t'=t_0}^{t-1} X_{t'}\right| > Ca_T\sqrt{t-t_0}\log T\right\}\right) 
    &\leq \frac{1}{a_T^2},
\end{align*}
and:
\begin{align*}
    \Pr \left(\bigcup_{t=1}^{t_0-1}\left\{ \left|\sum_{t'=t}^{t_0-1} X_{t'}\right| > Ca_T\sqrt{t_0-t}\log T\right\}\right) 
    &\leq \frac{1}{a^2_T},
\end{align*}
and:
\begin{align*}
    \Pr \left(\bigcup_{t=1}^{T}\left\{ \left|\sum_{t'=t}^{T} X_{t'}\right| > Ca_T\sqrt{T-t+1}\log T\right\}\right) 
    &\leq \frac{1}{a_T^2}.
\end{align*}

\end{lemma}

\begin{proof}
By Lemma \ref{lemma:Padilla23}, there is some constant $C > 0$ so that if we let $\nu = 1$ and $a = a_T^{-1}$, then:
\begin{align*}
    \Pr \left(\bigcup_{t=1}^\infty\left\{\left|\sum_{t'=1}^t X_{t'}\right| > Ca_T\sqrt{t}\left[\log t + 1\right]\right\}\right) 
    \leq \frac{1}{a_T^2}.
\end{align*}
Note that since $\{X_t\}_{t=1}^\infty$ is a stationary process, so we can shift the time indices of the sum by $t_0-1$ to get:
\small
\begin{align*}
    \frac{1}{a_T^2} &\geq \Pr \left(\bigcup_{t=1}^\infty\left\{\left|\sum_{t'=1}^t X_{t'}\right| > Ca_T\sqrt{t}\left[\log t + 1\right]\right\}\right) \\
    &= \Pr \left(\bigcup_{t=t_0+1}^\infty\left\{\left|\sum_{t'=t_0}^{t-1} X_{t'}\right| > C a_T\sqrt{t-t_0}\left[\log (t-t_0) + 1\right]\right\}\right) \tag{stationarity} \\
    &\geq \Pr \left(\bigcup_{t=t_0+1}^{T}\left\{\left|\sum_{t'=t_0}^{t-1} X_{t'}\right| > C a_T\sqrt{t-t_0}\log (t-t_0)\right\}\right)\\
    &\geq \Pr \left(\bigcup_{t=t_0+1}^{T}\left\{\left|\sum_{t'=t_0}^{t-1} X_{t'}\right| > C a_T\sqrt{t-t_0}\log T\right\}\right). \tag{$T > t-t_0$}
\end{align*}
\normalsize
Similarly:
\small
\begin{align*}
    \frac{1}{a_T^2} &\geq \Pr \left(\bigcup_{t=1}^\infty\left\{\left|\sum_{t'=1}^t X_{t'}\right| > Ca_T\sqrt{t} \left[\log t + 1\right]\right\}\right) \\
    &\geq \Pr \left(\bigcup_{t=1}^{t_0-1}\left\{\left|\sum_{t'=1}^t X_{t'}\right| > Ca_T\sqrt{t}\log t\right\}\right) \\
    &= \Pr \left(\bigcup_{t=1}^{t_0-1}\left\{\left|\sum_{t'=1}^{t_0 - t} X_{t'}\right| > Ca_T\sqrt{t_0- t}\log (t_0 - t)\right\}\right)  \\
    &\geq \Pr \left(\bigcup_{t=1}^{t_0-1}\left\{\left|\sum_{t'=t}^{t_0-1} X_{t'}\right| > Ca_T\sqrt{t_0-t}\log T\right\}\right). \tag{$T > t_0-t$}
\end{align*}
\normalsize
Lastly:
\small
\begin{align*}
     \frac{1}{a_T^2} &\geq \Pr \left(\bigcup_{t=1}^\infty\left\{\left|\sum_{t'=1}^t X_{t'}\right| > Ca_T\sqrt{t} \left[\log t + 1\right]\right\}\right) \\
     &\geq \Pr \left(\bigcup_{t=1}^{T}\left\{\left|\sum_{t'=1}^{t} X_{t'}\right| > Ca_T\sqrt{t}\log t\right\}\right) \\
    &= \Pr \left(\bigcup_{t=1}^{T}\left\{\left|\sum_{t'=1}^{T - t + 1} X_{t'}\right| > Ca_T\sqrt{T - t + 1}\log (T - t+1)\right\}\right)  \\
    &\geq \Pr \left(\bigcup_{t=1}^{T}\left\{\left|\sum_{t'=t}^{T} X_{t'}\right| > Ca_T\sqrt{T-t+1}\log T\right\}\right). \tag{$T > T-t+1$}
\end{align*}
\end{proof}